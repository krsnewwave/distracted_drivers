{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The changes here are:\n",
    "- Orthogonal weight initialization\n",
    "- Decreasing learning rate by step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from skimage import io, transform, exposure, color, util\n",
    "import os, itertools, sys\n",
    "from PIL import Image\n",
    "%pylab inline\n",
    "sys.setrecursionlimit(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_dir = \"/home/dylan/IdeaProjects/distracted_drivers/train/\"\n",
    "data_dir =  \"/media/dylan/Science/Kaggle-Data/distracted_drivers/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_volume_shape = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_img_file_PIL(file_path, size=(32,32)):\n",
    "    img = Image.open(file_path).convert('L')\n",
    "    img.thumbnail(size, Image.NEAREST)\n",
    "    data = np.array(img)\n",
    "    shape = data.shape\n",
    "    append_top = int(ceil(max(0, size[0] - shape[0])/2.0))\n",
    "    append_bot = int(floor(max(0, size[0] - shape[0])/2.0))\n",
    "    data = util.pad(data, ((append_top, append_bot),\n",
    "                           (0,0)), mode='constant', constant_values=0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_img_file(file_path, rescale=0.01):\n",
    "    img = io.imread(file_path)\n",
    "    img= color.rgb2gray(img)\n",
    "    return transform.rescale(img, rescale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image_gen_from_dir(directory, batch_size, num_categories, size=input_volume_shape):\n",
    "    result = {os.path.join(dp, f) : int(os.path.split(dp)[1]) for dp, dn, filenames in os.walk(data_dir) \n",
    "                  for f in filenames if os.path.splitext(f)[1] == '.jpg'}\n",
    "    # infinite loop\n",
    "    while True:\n",
    "        image_files = []\n",
    "        labels = []\n",
    "        # randomly choose batch size samples in result\n",
    "        for category in range(num_categories):\n",
    "            file_samples = np.random.choice([k for k, v in result.iteritems() if v == category], \n",
    "                             size=batch_size, replace=False)\n",
    "            for file_sample in file_samples:\n",
    "                image_files.append(read_img_file_PIL(file_sample, size=size))\n",
    "            labels.extend([v for v in itertools.repeat(category, batch_size)])\n",
    "\n",
    "        # end category loop\n",
    "        X = np.asarray(image_files, dtype=np.float32)\n",
    "        # -1 to 1 range\n",
    "        X = exposure.rescale_intensity(X, out_range=(-1,1))\n",
    "        y = np.asarray(labels, dtype=np.int32)\n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another loader, augmentation time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do 6 augmentations:\n",
    "\n",
    "\n",
    "    1.) Translation up to 10 pixels\n",
    "    2.) Rotation up to 15 degrees\n",
    "    3.) Zooming\n",
    "    4.) JPEG compression\n",
    "    5.) Sharpening\n",
    "    6.) Gamma correction\n",
    "\n",
    "\n",
    "We won't do flips since the dataset only contains images from the passenger seat. Perhaps we can revisit this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.transform import rotate, warp, AffineTransform\n",
    "from skimage import filters\n",
    "from scipy import ndimage, misc\n",
    "import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_translate(img):\n",
    "    shift_random = AffineTransform(translation=(randint(-10, 10), randint(-10, 10)))\n",
    "    min_value = 0 if min(img.ravel()) > 0 else min(img.ravel())\n",
    "    return np.float32(warp(img, shift_random, mode='constant', cval=min_value))\n",
    "\n",
    "def random_rotate(img):\n",
    "    min_value = 0 if min(img.ravel()) > 0 else min(img.ravel())\n",
    "    return np.float32(rotate(img, randint(-15, 15), mode='constant', cval=min_value))\n",
    "\n",
    "def random_zoom(img):\n",
    "    min_value = 0 if min(img.ravel()) > 0 else min(img.ravel())\n",
    "    scale_random = AffineTransform(scale=(uniform(0.9, 1.1), uniform(0.9, 1.1)))\n",
    "    return np.float32(warp(img, scale_random, mode='constant', cval=min_value))\n",
    "\n",
    "def random_compress(img):\n",
    "    max_v = np.ceil(img.max())\n",
    "    min_v = np.floor(img.min())\n",
    "    nd_im = exposure.rescale_intensity(img, out_range=(0, 1)).squeeze()\n",
    "    nd_im = np.ndarray.astype(nd_im * 255, np.uint8)\n",
    "    # nd_im = np.ndarray.astype(img * 255, np.uint8)\n",
    "    im = Image.fromarray(nd_im)\n",
    "    buf = StringIO.StringIO()\n",
    "    im.save(buf, \"JPEG\", quality=np.random.randint(95, 99))\n",
    "    buf.seek(0)\n",
    "    im2 = Image.open(buf)\n",
    "    x1 = exposure.rescale_intensity(np.ndarray.astype(np.array(im2), np.float32), out_range=(min_v, max_v))\n",
    "    return x1\n",
    "\n",
    "def random_sharpening(img):\n",
    "    blurred_f = ndimage.gaussian_filter(img, 0.5)\n",
    "    filter_blurred_f = ndimage.gaussian_filter(blurred_f, 1)\n",
    "    alpha = uniform(0.9, 1.2)\n",
    "    img = blurred_f + alpha * (blurred_f - filter_blurred_f)\n",
    "    return exposure.rescale_intensity(img, out_range=(-1 , 1))\n",
    "\n",
    "def random_gamma_correction(img):\n",
    "    max_v = np.ceil(img.max())\n",
    "    min_v = np.floor(img.min())\n",
    "    img = exposure.rescale_intensity(img, out_range=(0,1))\n",
    "    img = exposure.adjust_gamma(img, uniform(0.2, 0.8))\n",
    "    return exposure.rescale_intensity(img, out_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_aug(img):\n",
    "    choice = np.random.randint(0,6)\n",
    "    # choose from 4 different augmentations!\n",
    "    if choice == 0:\n",
    "        return random_translate(img)\n",
    "    elif choice == 1:\n",
    "        return random_rotate(img)\n",
    "    elif choice == 2:\n",
    "        return random_zoom(img)\n",
    "    elif choice == 3:\n",
    "        return random_compress(img)\n",
    "    elif choice == 4:\n",
    "        return random_sharpening(img)\n",
    "    else:\n",
    "        return random_gamma_correction(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_aug_batch(X, aug_algorithm):\n",
    "    for i in range(X.shape[0]):\n",
    "        X[i] = aug_algorithm(X[i])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_aug_gen(gen, aug_algorithm):\n",
    "    for batchX, batchY in gen:\n",
    "        yield random_aug_batch(batchX, aug_algorithm), batchY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Generator with cached elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threaded_generator(generator, num_cached=50):\n",
    "    import Queue\n",
    "    queue = Queue.Queue(maxsize=num_cached)\n",
    "    sentinel = object()  # guaranteed unique reference\n",
    "\n",
    "    # define producer (putting items into queue)\n",
    "    def producer():\n",
    "        for item in generator:\n",
    "            queue.put(item)\n",
    "        queue.put(sentinel)\n",
    "\n",
    "    # start producer (in a background thread)\n",
    "    import threading\n",
    "    thread = threading.Thread(target=producer)\n",
    "    thread.daemon = True\n",
    "    thread.start()\n",
    "\n",
    "    # run as consumer (read items from queue, in current thread)\n",
    "    item = queue.get()\n",
    "    while item is not sentinel:\n",
    "        yield item\n",
    "        queue.task_done()\n",
    "        item = queue.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 960 (CNMeM is disabled, CuDNN 4004)\n"
     ]
    }
   ],
   "source": [
    "from nolearn.lasagne import NeuralNet\n",
    "from lasagne.layers import DenseLayer, ReshapeLayer, Upscale2DLayer, Conv2DLayer, InputLayer, DropoutLayer, \\\n",
    "    MaxPool2DLayer, get_all_params, batch_norm, BatchNormLayer, FeaturePoolLayer\n",
    "import numpy as np\n",
    "from lasagne.nonlinearities import softmax, leaky_rectify, theano\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet, BatchIterator, PrintLayerInfo, objective\n",
    "from nolearn.lasagne import TrainSplit\n",
    "from common import EarlyStopping, EndTrainingFromEarlyStopping\n",
    "from lasagne.objectives import categorical_crossentropy, aggregate\n",
    "import cPickle as pickle\n",
    "from sklearn import metrics\n",
    "import time, logging, logging.config, logging.handlers\n",
    "from lasagne.init import Orthogonal\n",
    "from notebook_functions import load_best_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def batch_norm(s):\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from lasagne.layers.dnn import Conv2DDNNLayer, MaxPool2DDNNLayer\n",
    "    def conv_2_layer_stack(top, num_filters):\n",
    "        conv1 = batch_norm(Conv2DDNNLayer(top, num_filters, (3, 3), \n",
    "                stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv2 = batch_norm(Conv2DDNNLayer(conv1, num_filters, (3, 3), \n",
    "                stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        return MaxPool2DDNNLayer(conv2, (2, 2), 2)\n",
    "\n",
    "    def conv_3_layer_stack(top, num_filters):\n",
    "        conv1 = batch_norm(Conv2DDNNLayer(top, num_filters, (3, 3), \n",
    "                    stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv2 = batch_norm(Conv2DDNNLayer(conv1, num_filters, (3, 3), \n",
    "                    stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv3 = batch_norm(Conv2DDNNLayer(conv2, num_filters, (3, 3), \n",
    "                    stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        return MaxPool2DDNNLayer(conv3, (2, 2), 2)\n",
    "    \n",
    "    def conv_4_layer_stack(top, num_filters):\n",
    "        conv1 = batch_norm(Conv2DDNNLayer(top, num_filters, (3, 3), \n",
    "                    stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv2 = batch_norm(Conv2DDNNLayer(conv1, num_filters, (3, 3), \n",
    "                    stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv3 = batch_norm(Conv2DDNNLayer(conv2, num_filters, (3, 3), \n",
    "                    stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv4 = batch_norm(Conv2DDNNLayer(conv3, num_filters, (3, 3), \n",
    "                    stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        return MaxPool2DDNNLayer(conv4, (2, 2), 2)\n",
    "    \n",
    "    def conv_6_layer_stack(top, num_filters):\n",
    "        conv1 = batch_norm(Conv2DDNNLayer(top, num_filters, (3, 3), \n",
    "                    stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv2 = batch_norm(Conv2DDNNLayer(conv1, num_filters, (3, 3), \n",
    "                    stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv3 = batch_norm(Conv2DDNNLayer(conv2, num_filters, (3, 3), \n",
    "                    stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv4 = batch_norm(Conv2DDNNLayer(conv3, num_filters, (3, 3), \n",
    "                stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv5 = batch_norm(Conv2DDNNLayer(conv4, num_filters, (3, 3), \n",
    "                stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv6 = batch_norm(Conv2DDNNLayer(conv5, num_filters, (3, 3), \n",
    "                stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        return MaxPool2DLayer(conv6, (2, 2), 2)\n",
    "    \n",
    "except ImportError:\n",
    "    def conv_2_layer_stack(top, num_filters):\n",
    "        conv1 = batch_norm(Conv2DLayer(top, num_filters, (3, 3), stride=1, pad=1, nonlinearity=leaky_rectify))\n",
    "        conv2 = batch_norm(Conv2DLayer(conv1, num_filters, (3, 3), stride=1, pad=1, nonlinearity=leaky_rectify))\n",
    "        return MaxPool2DLayer(conv2, (2, 2), 2)\n",
    "\n",
    "    def conv_3_layer_stack(top, num_filters):\n",
    "        conv1 = batch_norm(Conv2DLayer(top, num_filters, (3, 3), stride=1, pad=1, nonlinearity=leaky_rectify))\n",
    "        conv2 = batch_norm(Conv2DLayer(conv1, num_filters, (3, 3), stride=1, pad=1, nonlinearity=leaky_rectify))\n",
    "        conv3 = batch_norm(Conv2DLayer(conv2, num_filters, (3, 3), stride=1, pad=1, nonlinearity=leaky_rectify))\n",
    "        return MaxPool2DLayer(conv3, (2, 2), 2)    \n",
    "    \n",
    "    def conv_4_layer_stack(top, num_filters):\n",
    "        conv1 = batch_norm(Conv2DLayer(top, num_filters, (3, 3), stride=1, pad=1, nonlinearity=leaky_rectify))\n",
    "        conv2 = batch_norm(Conv2DLayer(conv1, num_filters, (3, 3), stride=1, pad=1, nonlinearity=leaky_rectify))\n",
    "        conv3 = batch_norm(Conv2DLayer(conv2, num_filters, (3, 3), stride=1, pad=1, nonlinearity=leaky_rectify))\n",
    "        conv4 = batch_norm(Conv2DLayer(conv3, num_filters, (3, 3), stride=1, pad=1, nonlinearity=leaky_rectify))\n",
    "        return MaxPool2DLayer(conv4, (2, 2), 2)\n",
    "    \n",
    "    def conv_6_layer_stack(top, num_filters):\n",
    "        conv1 = batch_norm(Conv2DLayer(top, num_filters, (3, 3), stride=1, pad=1, nonlinearity=leaky_rectify))\n",
    "        conv2 = batch_norm(Conv2DLayer(conv1, num_filters, (3, 3), stride=1, pad=1, nonlinearity=leaky_rectify))\n",
    "        conv3 = batch_norm(Conv2DLayer(conv2, num_filters, (3, 3), stride=1, pad=1, nonlinearity=leaky_rectify))\n",
    "        conv4 = batch_norm(Conv2DLayer(conv3, num_filters, (3, 3), stride=1, pad=1, nonlinearity=leaky_rectify))\n",
    "        conv5 = batch_norm(Conv2DLayer(conv4, num_filters, (3, 3), stride=1, pad=1, nonlinearity=leaky_rectify))\n",
    "        conv6 = batch_norm(Conv2DLayer(conv5, num_filters, (3, 3), stride=1, pad=1, nonlinearity=leaky_rectify))\n",
    "        return MaxPool2DLayer(conv6, (2, 2), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 8\n",
    "input_layer = InputLayer((None, 1, input_volume_shape[0], input_volume_shape[1]))\n",
    "conv_stack_1 = conv_2_layer_stack(input_layer, 32)\n",
    "dropout1 = DropoutLayer(conv_stack_1, p=0.1)\n",
    "\n",
    "conv_stack_2 = conv_2_layer_stack(dropout1, 64)\n",
    "dropout2 = DropoutLayer(conv_stack_2, p=0.2)\n",
    "\n",
    "conv_stack_3 = conv_2_layer_stack(dropout2, 128)\n",
    "dropout3 = DropoutLayer(conv_stack_3, p=0.3)\n",
    "\n",
    "conv_stack_4 = conv_2_layer_stack(dropout3, 256)\n",
    "dropout4 = DropoutLayer(conv_stack_4, p=0.4)\n",
    "\n",
    "conv_stack_5 = conv_2_layer_stack(dropout4, 512)\n",
    "dropout17 = DropoutLayer(conv_stack_5, p=0.5)\n",
    "\n",
    "dense18 = DenseLayer(dropout17, 2048, nonlinearity=None)\n",
    "norm1 = BatchNormLayer(dense18)\n",
    "maxout1 = FeaturePoolLayer(norm1, k)\n",
    "dropout19 = DropoutLayer(maxout1, p=0.5)\n",
    "\n",
    "dense20 = DenseLayer(dropout19, 2048, nonlinearity=None)\n",
    "norm2 = BatchNormLayer(dense20)\n",
    "maxout2 = FeaturePoolLayer(norm2, k)\n",
    "\n",
    "softmax21 = DenseLayer(maxout2, 10, nonlinearity=softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality of Life Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "logging.config.fileConfig(\"logging-training.conf\")\n",
    "\n",
    "def regularization_objective(layers, lambda1=0., lambda2=0., *args, **kwargs):\n",
    "    # default loss\n",
    "    losses = objective(layers, *args, **kwargs)\n",
    "    # get layer weights except for the biases\n",
    "    weights = get_all_params(layers[-1], regularizable=True)\n",
    "    regularization_term = 0.0\n",
    "    # sum of abs weights for L1 regularization\n",
    "    if lambda1 != 0.0:\n",
    "        sum_abs_weights = sum([abs(w).sum() for w in weights])\n",
    "        regularization_term += (lambda1 * sum_abs_weights) \n",
    "    # sum of squares (sum(theta^2))\n",
    "    if lambda2 != 0.0:\n",
    "        sum_squared_weights = (1 / 2.0) * sum([(w ** 2).sum() for w in weights])\n",
    "        regularization_term += (lambda2 * sum_squared_weights)\n",
    "    # add weights to regular loss\n",
    "    losses += regularization_term\n",
    "    return losses\n",
    "\n",
    "def eval_regularization(net):\n",
    "    if net.objective_lambda1 == 0 and net.objective_lambda2 == 0:\n",
    "        return 0\n",
    "    # check the loss if the regularization term is not overpowering the loss\n",
    "    weights = get_all_params(net.layers_[-1], regularizable=True)\n",
    "    # sum of abs weights for L1 regularization\n",
    "    sum_abs_weights = sum([abs(w).sum() for w in weights])\n",
    "    # sum of squares (sum(theta^2))\n",
    "    sum_squared_weights = (1 / 2.0) * sum([(w ** 2).sum() for w in weights])\n",
    "    # add weights to regular loss\n",
    "    regularization_term = (net.objective_lambda1 * sum_abs_weights) \\\n",
    "                          + (net.objective_lambda2 * sum_squared_weights)\n",
    "    return regularization_term\n",
    "\n",
    "\n",
    "def print_regularization_term(net):\n",
    "    if net.objective_lambda1 > 0.0 or net.objective_lambda2 > 0.0:\n",
    "        regularization_term = eval_regularization(net)\n",
    "        print \"Regularization term: {}\".format(regularization_term.eval())\n",
    "\n",
    "def validation_set_loss(_net, _X, _y):\n",
    "    \"\"\"We need this to track the validation loss\"\"\"\n",
    "    _yb = _net.predict_proba(_X)\n",
    "    _y_pred = np.argmax(_yb, axis=1)\n",
    "    _acc = metrics.accuracy_score(_y, _y_pred)\n",
    "    loss = aggregate(categorical_crossentropy(_yb, _y))\n",
    "    loss += eval_regularization(_net)\n",
    "    return loss, _acc\n",
    "\n",
    "\n",
    "def store_model(model_file_name, net):\n",
    "    directory_name = os.path.dirname(model_file_name)\n",
    "    model_file_name = os.path.basename(model_file_name)\n",
    "    if not os.path.exists(directory_name):\n",
    "        os.makedirs(directory_name)\n",
    "    # write model\n",
    "    output_model_file_name = os.path.join(directory_name, model_file_name)\n",
    "    start_write_time = time.time()\n",
    "    if os.path.isfile(output_model_file_name):\n",
    "        os.remove(output_model_file_name)\n",
    "    with open(output_model_file_name, 'wb') as experiment_model:\n",
    "        pickle.dump(net, experiment_model)\n",
    "    total_write_time = time.time() - start_write_time\n",
    "    m, s = divmod(total_write_time, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    logging.log(logging.INFO, \"Duration of saving to disk: %0d:%02d:%02d\", h, m, s)\n",
    "\n",
    "def write_validation_loss_and_store_best(validation_file_name, best_weights_file_name, \n",
    "                                         net, X_val, y_val, best_vloss, best_acc):\n",
    "    # write validation loss\n",
    "    start_validate_time = time.time()\n",
    "    vLoss, vAcc = validation_set_loss(net, X_val, y_val)\n",
    "    loss = vLoss.eval()\n",
    "    current_epoch = net.train_history_[-1]['epoch']\n",
    "    with open(validation_file_name, 'a') as validation_file:\n",
    "        validation_file.write(\"{}, {}, {}\\n\".format(current_epoch, loss, vAcc))\n",
    "\n",
    "    total_validate_time = time.time() - start_validate_time\n",
    "    m, s = divmod(total_validate_time, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    logging.log(logging.INFO, \"Duration of validation: %0d:%02d:%02d\", h, m, s)\n",
    "    \n",
    "    # store best weights here\n",
    "    if loss < best_vloss:\n",
    "        start_bw_time = time.time()\n",
    "        best_vloss = loss\n",
    "        best_acc = vAcc\n",
    "        with open(best_weights_file_name, 'wb') as best_model_file:\n",
    "            pickle.dump(net.get_all_params_values(), best_model_file, -1)\n",
    "            \n",
    "    return best_vloss, best_acc\n",
    "\n",
    "\n",
    "class AdjustVariableWithStepSize(object):\n",
    "    \"\"\"This class adjusts any variable during training\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, start=0.03, steps=3, after_epochs=2000):\n",
    "        self.name = name\n",
    "        self.start = start\n",
    "        self.steps=steps\n",
    "        self.after_epochs=after_epochs\n",
    "        self.ls = []\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if not self.ls:\n",
    "            for i in range(self.steps):\n",
    "                self.ls.extend(np.repeat(self.start/(np.power(10,i)), self.after_epochs))\n",
    "\n",
    "        try:\n",
    "            epoch = train_history[-1]['epoch']\n",
    "            new_value = np.float32(self.ls[epoch - 1])\n",
    "            getattr(nn, self.name).set_value(new_value)\n",
    "        except IndexError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lambda1 = 0.0\n",
    "lambda2 = 5e-3\n",
    "\n",
    "net = NeuralNet(\n",
    "    layers=softmax21,\n",
    "    max_epochs=1,\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=theano.shared(np.float32(0.001)),\n",
    "    update_momentum = 0.99,\n",
    "    # update=adam,\n",
    "    on_epoch_finished=[\n",
    "        EarlyStopping(patience=1000),\n",
    "        AdjustVariableWithStepSize('update_learning_rate', start=0.001, steps=2, after_epochs=8000),\n",
    "    ],\n",
    "    on_training_finished=[\n",
    "        EndTrainingFromEarlyStopping()\n",
    "    ],\n",
    "    objective=regularization_objective,\n",
    "    objective_lambda2=lambda2,\n",
    "    objective_lambda1=lambda1,\n",
    "    batch_iterator_train=BatchIterator(batch_size=100),\n",
    "    train_split=TrainSplit(\n",
    "        eval_size=0.25),\n",
    "    # train_split=TrainSplit(eval_size=0.0),\n",
    "    verbose=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = PrintLayerInfo()\n",
    "net.initialize()\n",
    "# p(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load cnn instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model from the beginning net.vgg.large.l2.5e3.orthog-norm-maxout8-lr.2.steps\n"
     ]
    }
   ],
   "source": [
    "dir_name = 'net.vgg.large.l2.5e3.orthog-norm-maxout8-lr.2.steps'\n",
    "validation_file_name = \"{}/vloss-{}.txt\".format(dir_name, dir_name)\n",
    "model_file_name = \"{}/{}.pickle\".format(dir_name, dir_name)\n",
    "best_weights_file_name = \"{}/bw-{}.weights\".format(dir_name, dir_name)\n",
    "if os.path.exists(dir_name):\n",
    "    print \"Model exists. Loading {}.\".format(dir_name)\n",
    "    with open(model_file_name, 'rb') as reader:\n",
    "        net = pickle.load(reader)\n",
    "else:\n",
    "    print \"Training model from the beginning {}\".format(dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "load_best_weights(best_weights_file_name, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from nolearn.lasagne.visualize import plot_loss\n",
    "plt.figure( figsize=(15,9))\n",
    "plt.ylim([0.1,0.5])\n",
    "plt.plot([v['valid_loss'] for v in net.train_history_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# just this time.\n",
    "net.on_epoch_finished.pop(1)\n",
    "print net.on_epoch_finished\n",
    "net.update_learning_rate=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_dir =  \"/media/dylan/Science/Kaggle-Data/distracted_drivers/val/\"\n",
    "X_val, y_val = image_gen_from_dir(val_dir, 40, 10, size=input_volume_shape).next()\n",
    "X_val = X_val.reshape(-1, 1, input_volume_shape[0], input_volume_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 22029994 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "name               size          total    cap.Y    cap.X    cov.Y    cov.X    filter Y    filter X    field Y    field X\n",
      "-----------------  ----------  -------  -------  -------  -------  -------  ----------  ----------  ---------  ---------\n",
      "InputLayer         1x128x128     16384   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "Conv2DDNNLayer     32x128x128   524288   100.00   100.00     2.34     2.34           3           3          3          3\n",
      "BatchNormLayer     32x128x128   524288   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "NonlinearityLayer  32x128x128   524288   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "Conv2DDNNLayer     32x128x128   524288   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "BatchNormLayer     32x128x128   524288   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "NonlinearityLayer  32x128x128   524288   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "MaxPool2DDNNLayer  32x64x64     131072   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "DropoutLayer       32x64x64     131072   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "Conv2DDNNLayer     64x64x64     262144   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "BatchNormLayer     64x64x64     262144   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "NonlinearityLayer  64x64x64     262144   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "Conv2DDNNLayer     64x64x64     262144   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "BatchNormLayer     64x64x64     262144   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "NonlinearityLayer  64x64x64     262144   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "MaxPool2DDNNLayer  64x32x32      65536   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "DropoutLayer       64x32x32      65536   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "Conv2DDNNLayer     128x32x32    131072   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "BatchNormLayer     128x32x32    131072   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "NonlinearityLayer  128x32x32    131072   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "Conv2DDNNLayer     128x32x32    131072   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "BatchNormLayer     128x32x32    131072   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "NonlinearityLayer  128x32x32    131072   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "MaxPool2DDNNLayer  128x16x16     32768   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "DropoutLayer       128x16x16     32768   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "Conv2DDNNLayer     256x16x16     65536   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "BatchNormLayer     256x16x16     65536   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "NonlinearityLayer  256x16x16     65536   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "Conv2DDNNLayer     256x16x16     65536   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "BatchNormLayer     256x16x16     65536   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "NonlinearityLayer  256x16x16     65536   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "MaxPool2DDNNLayer  256x8x8       16384   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "DropoutLayer       256x8x8       16384   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "Conv2DDNNLayer     512x8x8       32768   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "BatchNormLayer     512x8x8       32768   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "NonlinearityLayer  512x8x8       32768   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "Conv2DDNNLayer     512x8x8       32768   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "BatchNormLayer     512x8x8       32768   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "NonlinearityLayer  512x8x8       32768   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "MaxPool2DDNNLayer  512x4x4        8192   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "DropoutLayer       512x4x4        8192   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "DenseLayer         2048           2048   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "BatchNormLayer     2048           2048   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "FeaturePoolLayer   256             256   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "DropoutLayer       256             256   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "DenseLayer         2048           2048   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "BatchNormLayer     2048           2048   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "FeaturePoolLayer   256             256   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "DenseLayer         10               10   100.00   100.00   100.00   100.00         128         128        128        128\n",
      "\n",
      "Explanation\n",
      "    X, Y:    image dimensions\n",
      "    cap.:    learning capacity\n",
      "    cov.:    coverage of image\n",
      "    \u001b[35mmagenta\u001b[0m: capacity too low (<1/6)\n",
      "    \u001b[36mcyan\u001b[0m:    image coverage too high (>100%)\n",
      "    \u001b[31mred\u001b[0m:     capacity too low and coverage too high\n",
      "\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1      \u001b[36m33.25506\u001b[0m      \u001b[32m31.78047\u001b[0m      1.04640      0.10000  1.03s\n",
      "      2      \u001b[36m33.17589\u001b[0m      31.78650      1.04371      0.06667  0.99s\n",
      "      3      \u001b[36m32.99888\u001b[0m      31.79005      1.03803      0.06667  0.99s\n",
      "      4      \u001b[36m32.76854\u001b[0m      31.79113      1.03074      0.06667  0.99s\n",
      "      5      \u001b[36m32.49733\u001b[0m      31.79183      1.02219      0.10000  0.99s\n",
      "      6      \u001b[36m32.44246\u001b[0m      31.78381      1.02072      0.16667  0.98s\n",
      "      7      \u001b[36m32.39525\u001b[0m      31.78540      1.01919      0.10000  0.99s\n",
      "      8      \u001b[36m32.12280\u001b[0m      \u001b[32m31.78002\u001b[0m      1.01079      0.03333  1.00s\n",
      "      9      32.20690      31.78030      1.01342      0.06667  0.99s\n",
      "     10      32.13252      31.78701      1.01087      0.13333  1.00s\n",
      "     11      \u001b[36m32.00925\u001b[0m      \u001b[32m31.77393\u001b[0m      1.00741      0.13333  1.01s\n",
      "     12      32.21346      31.79861      1.01305      0.10000  1.02s\n",
      "     13      32.43863      31.80940      1.01978      0.10000  0.99s\n",
      "     14      32.30440      31.82019      1.01522      0.10000  0.98s\n",
      "     15      32.48502      31.84547      1.02008      0.10000  0.99s\n",
      "     16      32.65747      31.85558      1.02517      0.10000  0.98s\n",
      "     17      32.57602      31.86535      1.02230      0.10000  0.98s\n",
      "     18      32.63330      31.84866      1.02464      0.10000  0.98s\n",
      "     19      32.59288      31.83547      1.02379      0.10000  0.99s\n",
      "     20      32.59788      31.78869      1.02546      0.10000  1.00s\n",
      "     21      32.40544      31.78866      1.01940      0.10000  1.01s\n",
      "     22      32.20409      \u001b[32m31.75043\u001b[0m      1.01429      0.10000  0.98s\n",
      "     23      32.16093      \u001b[32m31.71952\u001b[0m      1.01392      0.10000  0.95s\n",
      "     24      \u001b[36m31.95499\u001b[0m      31.72150      1.00736      0.16667  1.00s\n",
      "     25      32.12714      \u001b[32m31.68436\u001b[0m      1.01397      0.03333  0.99s\n",
      "     26      \u001b[36m31.87635\u001b[0m      31.70796      1.00531      0.06667  1.00s\n",
      "     27      31.97775      31.72711      1.00790      0.10000  1.00s\n",
      "     28      32.12251      31.69959      1.01334      0.06667  1.00s\n",
      "     29      32.03930      31.70591      1.01052      0.06667  0.99s\n",
      "     30      32.05185      31.72498      1.01030      0.13333  0.99s\n",
      "     31      32.19906      31.70462      1.01560      0.16667  0.97s\n",
      "     32      31.96948      31.68882      1.00886      0.10000  0.99s\n",
      "     33      32.12095      31.73195      1.01226      0.10000  1.01s\n",
      "     34      32.28888      31.70193      1.01851      0.10000  0.99s\n",
      "     35      32.10909      \u001b[32m31.67241\u001b[0m      1.01379      0.16667  1.00s\n",
      "     36      32.12541      \u001b[32m31.62836\u001b[0m      1.01572      0.13333  1.01s\n",
      "     37      31.98480      \u001b[32m31.62747\u001b[0m      1.01130      0.06667  1.00s\n",
      "     38      \u001b[36m31.84256\u001b[0m      \u001b[32m31.59635\u001b[0m      1.00779      0.06667  1.00s\n",
      "     39      \u001b[36m31.76545\u001b[0m      31.61071      1.00490      0.10000  1.01s\n",
      "     40      31.86823      31.60493      1.00833      0.10000  1.00s\n",
      "     41      31.93109      \u001b[32m31.58243\u001b[0m      1.01104      0.16667  1.00s\n",
      "     42      31.78740      31.59209      1.00618      0.10000  0.99s\n",
      "     43      31.86057      \u001b[32m31.56188\u001b[0m      1.00946      0.13333  1.01s\n",
      "     44      31.78907      31.59924      1.00601      0.10000  1.02s\n",
      "     45      \u001b[36m31.66023\u001b[0m      31.59312      1.00212      0.13333  1.00s\n",
      "     46      31.81987      31.58217      1.00753      0.10000  1.00s\n",
      "     47      31.84785      31.59037      1.00815      0.13333  1.00s\n",
      "     48      31.90572      31.59439      1.00985      0.06667  0.99s\n",
      "     49      31.86822      \u001b[32m31.55051\u001b[0m      1.01007      0.13333  0.99s\n",
      "     50      31.93616      31.57936      1.01130      0.06667  1.00s\n",
      "     51      31.87253      31.57030      1.00957      0.13333  1.01s\n",
      "     52      31.69820      \u001b[32m31.50569\u001b[0m      1.00611      0.06667  1.01s\n",
      "     53      31.68344      \u001b[32m31.48365\u001b[0m      1.00635      0.13333  1.01s\n",
      "     54      31.70494      31.49885      1.00654      0.10000  0.99s\n",
      "     55      \u001b[36m31.65168\u001b[0m      \u001b[32m31.46290\u001b[0m      1.00600      0.10000  0.99s\n",
      "     56      31.75206      \u001b[32m31.44831\u001b[0m      1.00966      0.10000  0.99s\n",
      "     57      31.68836      31.46900      1.00697      0.10000  1.00s\n",
      "     58      \u001b[36m31.49895\u001b[0m      \u001b[32m31.40435\u001b[0m      1.00301      0.10000  0.99s\n",
      "     59      31.52123      31.43587      1.00272      0.13333  1.00s\n",
      "     60      31.60312      31.42969      1.00552      0.13333  0.99s\n",
      "     61      31.63642      31.41870      1.00693      0.10000  1.01s\n",
      "     62      \u001b[36m31.48268\u001b[0m      31.42694      1.00177      0.10000  0.99s\n",
      "     63      31.53871      31.42119      1.00374      0.10000  1.00s\n",
      "     64      31.56316      31.41545      1.00470      0.13333  0.99s\n",
      "     65      31.49996      \u001b[32m31.38778\u001b[0m      1.00357      0.10000  1.00s\n",
      "     66      31.54456      \u001b[32m31.33249\u001b[0m      1.00677      0.13333  1.01s\n",
      "     67      31.62712      \u001b[32m31.33192\u001b[0m      1.00942      0.10000  1.00s\n",
      "     68      31.61530      31.33798      1.00885      0.16667  1.00s\n",
      "     69      31.53901      \u001b[32m31.32602\u001b[0m      1.00680      0.16667  0.99s\n",
      "     70      31.49148      \u001b[32m31.28814\u001b[0m      1.00650      0.06667  0.99s\n",
      "     71      \u001b[36m31.39332\u001b[0m      31.30571      1.00280      0.10000  0.97s\n",
      "     72      31.50287      31.30611      1.00629      0.03333  0.99s\n",
      "     73      31.47696      \u001b[32m31.25891\u001b[0m      1.00698      0.16667  0.99s\n",
      "     74      31.41952      31.31381      1.00338      0.10000  1.00s\n",
      "     75      31.59819      31.26338      1.01071      0.06667  1.00s\n",
      "     76      31.40242      31.27527      1.00407      0.10000  1.00s\n",
      "     77      \u001b[36m31.26772\u001b[0m      \u001b[32m31.24176\u001b[0m      1.00083      0.03333  1.00s\n",
      "     78      31.61490      \u001b[32m31.18827\u001b[0m      1.01368      0.10000  0.99s\n",
      "     79      31.52178      31.20059      1.01029      0.03333  1.00s\n",
      "     80      \u001b[36m31.26742\u001b[0m      31.21463      1.00169      0.06667  1.01s\n",
      "     81      31.32435      \u001b[32m31.15311\u001b[0m      1.00550      0.06667  1.00s\n",
      "     82      31.37941      31.17708      1.00649      0.06667  1.01s\n",
      "     83      31.31854      \u001b[32m31.14687\u001b[0m      1.00551      0.10000  0.99s\n",
      "     84      31.27228      \u001b[32m31.12518\u001b[0m      1.00473      0.06667  0.99s\n",
      "     85      31.32556      31.13277      1.00619      0.00000  1.00s\n",
      "     86      \u001b[36m31.19910\u001b[0m      \u001b[32m31.01919\u001b[0m      1.00580      0.20000  0.99s\n",
      "     87      31.38416      31.09854      1.00918      0.13333  1.01s\n",
      "     88      \u001b[36m31.07056\u001b[0m      31.13755      0.99785      0.03333  1.01s\n",
      "     89      31.23056      31.10376      1.00408      0.06667  1.01s\n",
      "     90      31.37108      31.08564      1.00918      0.03333  0.98s\n",
      "     91      31.15860      31.05631      1.00329      0.10000  0.96s\n",
      "     92      31.23090      31.03073      1.00645      0.06667  0.94s\n",
      "     93      \u001b[36m31.04417\u001b[0m      31.08680      0.99863      0.13333  0.96s\n",
      "     94      31.11362      \u001b[32m31.01442\u001b[0m      1.00320      0.16667  0.94s\n",
      "     95      \u001b[36m30.97961\u001b[0m      31.03494      0.99822      0.06667  0.98s\n",
      "     96      31.07029      \u001b[32m30.95866\u001b[0m      1.00361      0.13333  0.94s\n",
      "     97      31.05484      31.01039      1.00143      0.06667  0.95s\n",
      "     98      31.06017      30.98117      1.00255      0.13333  0.96s\n",
      "     99      30.98125      \u001b[32m30.92967\u001b[0m      1.00167      0.16667  1.01s\n",
      "    100      31.09165      30.94289      1.00481      0.10000  0.95s\n",
      "    101      \u001b[36m30.93985\u001b[0m      \u001b[32m30.88714\u001b[0m      1.00171      0.10000  0.99s\n",
      "    102      31.05118      30.92863      1.00396      0.10000  0.96s\n",
      "    103      31.07018      30.89117      1.00579      0.06667  0.95s\n",
      "    104      31.20908      30.89388      1.01020      0.16667  0.94s\n"
     ]
    }
   ],
   "source": [
    "image_gen = image_gen_from_dir(data_dir, 10, 10, size=input_volume_shape)\n",
    "gen = random_aug_gen(image_gen, random_aug)\n",
    "threaded_gen = threaded_generator(gen, num_cached=100)\n",
    "\n",
    "ops_every = 500\n",
    "best_acc = 0.0\n",
    "best_vloss = np.inf\n",
    "\n",
    "start_time = time.time()\n",
    "try:\n",
    "    for step, (inputs, targets) in enumerate(threaded_gen):\n",
    "        shape = inputs.shape\n",
    "        net.fit(inputs.reshape(shape[0],1, shape[1], shape[2]), targets)\n",
    "        if (step + 1) % ops_every == 0:\n",
    "            print_regularization_term(net)\n",
    "            store_model(model_file_name, net)\n",
    "            # center validation\n",
    "            best_vloss, best_acc = write_validation_loss_and_store_best(\n",
    "                validation_file_name, best_weights_file_name, net, X_val, y_val, best_vloss, best_acc)\n",
    "            \n",
    "except StopIteration:\n",
    "    # terminate if already early stopping\n",
    "    with open(model_file_name, 'wb') as writer:\n",
    "        pickle.dump(net, writer)\n",
    "    total_time = time.time() - start_time \n",
    "    print(\"Training successful by early stopping. Elapsed: {}\".format(total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from notebook_functions import plot_validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_validation_loss(net, validation_file_name, ylim=[0, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
