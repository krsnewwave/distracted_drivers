{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The changes here are larger images but same maxout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from skimage import io, transform, exposure, color, util\n",
    "import os, itertools, sys\n",
    "from PIL import Image\n",
    "%pylab inline\n",
    "sys.setrecursionlimit(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_dir = \"/home/dylan/IdeaProjects/distracted_drivers/train/\"\n",
    "data_dir =  \"/media/dylan/Science/Kaggle-Data/distracted_drivers/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_volume_shape = (261, 261)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_img_file_PIL(file_path, size=(32,32)):\n",
    "    img = Image.open(file_path).convert('L')\n",
    "    img.thumbnail(size, Image.NEAREST)\n",
    "    data = np.array(img)\n",
    "    shape = data.shape\n",
    "    append_top = int(ceil(max(0, size[0] - shape[0])/2.0))\n",
    "    append_bot = int(floor(max(0, size[0] - shape[0])/2.0))\n",
    "    data = util.pad(data, ((append_top, append_bot),\n",
    "                           (0,0)), mode='constant', constant_values=0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_img_file(file_path, rescale=0.01):\n",
    "    img = io.imread(file_path)\n",
    "    img= color.rgb2gray(img)\n",
    "    return transform.rescale(img, rescale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image_gen_from_dir(directory, batch_size, num_categories, size=input_volume_shape):\n",
    "    result = {os.path.join(dp, f) : int(os.path.split(dp)[1]) for dp, dn, filenames in os.walk(data_dir) \n",
    "                  for f in filenames if os.path.splitext(f)[1] == '.jpg'}\n",
    "    # infinite loop\n",
    "    while True:\n",
    "        image_files = []\n",
    "        labels = []\n",
    "        # randomly choose batch size samples in result\n",
    "        for category in range(num_categories):\n",
    "            file_samples = np.random.choice([k for k, v in result.iteritems() if v == category], \n",
    "                             size=batch_size, replace=False)\n",
    "            for file_sample in file_samples:\n",
    "                image_files.append(read_img_file_PIL(file_sample, size=size))\n",
    "            labels.extend([v for v in itertools.repeat(category, batch_size)])\n",
    "\n",
    "        # end category loop\n",
    "        X = np.asarray(image_files, dtype=np.float32)\n",
    "        # -1 to 1 range\n",
    "        X = exposure.rescale_intensity(X, out_range=(-1,1))\n",
    "        y = np.asarray(labels, dtype=np.int32)\n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another loader, augmentation time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do 6 augmentations:\n",
    "\n",
    "\n",
    "    1.) Translation up to 10 pixels\n",
    "    2.) Rotation up to 15 degrees\n",
    "    3.) Zooming\n",
    "    4.) JPEG compression\n",
    "    5.) Sharpening\n",
    "    6.) Gamma correction\n",
    "\n",
    "\n",
    "We won't do flips since the dataset only contains images from the passenger seat. Perhaps we can revisit this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.transform import rotate, warp, AffineTransform\n",
    "from skimage import filters\n",
    "from scipy import ndimage, misc\n",
    "import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_translate(img):\n",
    "    shift_random = AffineTransform(translation=(randint(-10, 10), randint(-10, 10)))\n",
    "    min_value = 0 if min(img.ravel()) > 0 else min(img.ravel())\n",
    "    return np.float32(warp(img, shift_random, mode='constant', cval=min_value))\n",
    "\n",
    "def random_rotate(img):\n",
    "    min_value = 0 if min(img.ravel()) > 0 else min(img.ravel())\n",
    "    return np.float32(rotate(img, randint(-15, 15), mode='constant', cval=min_value))\n",
    "\n",
    "def random_zoom(img):\n",
    "    min_value = 0 if min(img.ravel()) > 0 else min(img.ravel())\n",
    "    scale_random = AffineTransform(scale=(uniform(0.9, 1.1), uniform(0.9, 1.1)))\n",
    "    return np.float32(warp(img, scale_random, mode='constant', cval=min_value))\n",
    "\n",
    "def random_compress(img):\n",
    "    max_v = np.ceil(img.max())\n",
    "    min_v = np.floor(img.min())\n",
    "    nd_im = exposure.rescale_intensity(img, out_range=(0, 1)).squeeze()\n",
    "    nd_im = np.ndarray.astype(nd_im * 255, np.uint8)\n",
    "    # nd_im = np.ndarray.astype(img * 255, np.uint8)\n",
    "    im = Image.fromarray(nd_im)\n",
    "    buf = StringIO.StringIO()\n",
    "    im.save(buf, \"JPEG\", quality=np.random.randint(95, 99))\n",
    "    buf.seek(0)\n",
    "    im2 = Image.open(buf)\n",
    "    x1 = exposure.rescale_intensity(np.ndarray.astype(np.array(im2), np.float32), out_range=(min_v, max_v))\n",
    "    return x1\n",
    "\n",
    "def random_sharpening(img):\n",
    "    blurred_f = ndimage.gaussian_filter(img, 0.5)\n",
    "    filter_blurred_f = ndimage.gaussian_filter(blurred_f, 1)\n",
    "    alpha = uniform(0.9, 1.2)\n",
    "    img = blurred_f + alpha * (blurred_f - filter_blurred_f)\n",
    "    return exposure.rescale_intensity(img, out_range=(-1 , 1))\n",
    "\n",
    "def random_gamma_correction(img):\n",
    "    max_v = np.ceil(img.max())\n",
    "    min_v = np.floor(img.min())\n",
    "    img = exposure.rescale_intensity(img, out_range=(0,1))\n",
    "    img = exposure.adjust_gamma(img, uniform(0.2, 0.8))\n",
    "    return exposure.rescale_intensity(img, out_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_aug(img):\n",
    "    choice = np.random.randint(0,6)\n",
    "    # choose from 4 different augmentations!\n",
    "    if choice == 0:\n",
    "        return random_translate(img)\n",
    "    elif choice == 1:\n",
    "        return random_rotate(img)\n",
    "    elif choice == 2:\n",
    "        return random_zoom(img)\n",
    "    elif choice == 3:\n",
    "        return random_compress(img)\n",
    "    elif choice == 4:\n",
    "        return random_sharpening(img)\n",
    "    else:\n",
    "        return random_gamma_correction(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_aug_batch(X, aug_algorithm):\n",
    "    for i in range(X.shape[0]):\n",
    "        X[i] = aug_algorithm(X[i])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_aug_gen(gen, aug_algorithm):\n",
    "    for batchX, batchY in gen:\n",
    "        yield random_aug_batch(batchX, aug_algorithm), batchY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Generator with cached elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threaded_generator(generator, num_cached=50):\n",
    "    import Queue\n",
    "    queue = Queue.Queue(maxsize=num_cached)\n",
    "    sentinel = object()  # guaranteed unique reference\n",
    "\n",
    "    # define producer (putting items into queue)\n",
    "    def producer():\n",
    "        for item in generator:\n",
    "            queue.put(item)\n",
    "        queue.put(sentinel)\n",
    "\n",
    "    # start producer (in a background thread)\n",
    "    import threading\n",
    "    thread = threading.Thread(target=producer)\n",
    "    thread.daemon = True\n",
    "    thread.start()\n",
    "\n",
    "    # run as consumer (read items from queue, in current thread)\n",
    "    item = queue.get()\n",
    "    while item is not sentinel:\n",
    "        yield item\n",
    "        queue.task_done()\n",
    "        item = queue.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 960 (CNMeM is disabled, CuDNN 4004)\n"
     ]
    }
   ],
   "source": [
    "from nolearn.lasagne import NeuralNet\n",
    "from lasagne.layers import DenseLayer, ReshapeLayer, Upscale2DLayer, Conv2DLayer, InputLayer, DropoutLayer, \\\n",
    "    MaxPool2DLayer, get_all_params, batch_norm, BatchNormLayer, FeaturePoolLayer\n",
    "import numpy as np\n",
    "from lasagne.nonlinearities import softmax, leaky_rectify, theano\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet, BatchIterator, PrintLayerInfo, objective\n",
    "from nolearn.lasagne import TrainSplit\n",
    "from common import EarlyStopping, EndTrainingFromEarlyStopping\n",
    "from lasagne.objectives import categorical_crossentropy, aggregate\n",
    "import cPickle as pickle\n",
    "from sklearn import metrics\n",
    "import time, logging, logging.config, logging.handlers\n",
    "from lasagne.init import Orthogonal\n",
    "from notebook_functions import load_best_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def batch_norm(s):\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from lasagne.layers.dnn import Conv2DDNNLayer, MaxPool2DDNNLayer\n",
    "    def conv_2_layer_stack(top, num_filters, pad=1):\n",
    "        conv1 = batch_norm(Conv2DDNNLayer(top, num_filters, (3, 3), \n",
    "                stride=1, pad=pad, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv2 = batch_norm(Conv2DDNNLayer(conv1, num_filters, (3, 3), \n",
    "                stride=1, pad=pad, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        return MaxPool2DDNNLayer(conv2, (2, 2), 2)\n",
    "\n",
    "    def conv_3_layer_stack(top, num_filters, pad=1):\n",
    "        conv1 = batch_norm(Conv2DDNNLayer(top, num_filters, (3, 3), \n",
    "                    stride=1, pad=pad, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv2 = batch_norm(Conv2DDNNLayer(conv1, num_filters, (3, 3), \n",
    "                    stride=1, pad=pad, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv3 = batch_norm(Conv2DDNNLayer(conv2, num_filters, (3, 3), \n",
    "                    stride=1, pad=pad, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        return MaxPool2DDNNLayer(conv3, (2, 2), 2)\n",
    "    \n",
    "    def conv_4_layer_stack(top, num_filters, pad=1):\n",
    "        conv1 = batch_norm(Conv2DDNNLayer(top, num_filters, (3, 3), \n",
    "                    stride=1, pad=pad, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv2 = batch_norm(Conv2DDNNLayer(conv1, num_filters, (3, 3), \n",
    "                    stride=1, pad=pad, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv3 = batch_norm(Conv2DDNNLayer(conv2, num_filters, (3, 3), \n",
    "                    stride=1, pad=pad, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv4 = batch_norm(Conv2DDNNLayer(conv3, num_filters, (3, 3), \n",
    "                    stride=1, pad=pad, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        return MaxPool2DDNNLayer(conv4, (2, 2), 2)\n",
    "    \n",
    "    def conv_6_layer_stack(top, num_filters, pad=1):\n",
    "        conv1 = batch_norm(Conv2DDNNLayer(top, num_filters, (3, 3), \n",
    "                    stride=1, pad=pad, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv2 = batch_norm(Conv2DDNNLayer(conv1, num_filters, (3, 3), \n",
    "                    stride=1, pad=pad, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv3 = batch_norm(Conv2DDNNLayer(conv2, num_filters, (3, 3), \n",
    "                    stride=1, pad=pad, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv4 = batch_norm(Conv2DDNNLayer(conv3, num_filters, (3, 3), \n",
    "                stride=1, pad=pad, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv5 = batch_norm(Conv2DDNNLayer(conv4, num_filters, (3, 3), \n",
    "                stride=1, pad=pad, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        conv6 = batch_norm(Conv2DDNNLayer(conv5, num_filters, (3, 3), \n",
    "                stride=1, pad=pad, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "        return MaxPool2DLayer(conv6, (2, 2), 2)\n",
    "    \n",
    "except ImportError:\n",
    "    def conv_2_layer_stack(top, num_filters, pad=1):\n",
    "        conv1 = batch_norm(Conv2DLayer(\n",
    "                top, num_filters, (3, 3), stride=1, pad=pad, nonlinearity=leaky_rectify))\n",
    "        conv2 = batch_norm(Conv2DLayer(\n",
    "                conv1, num_filters, (3, 3), stride=1, pad=pad, nonlinearity=leaky_rectify))\n",
    "        return MaxPool2DLayer(conv2, (2, 2), 2)\n",
    "\n",
    "    def conv_3_layer_stack(top, num_filters, pad=1):\n",
    "        conv1 = batch_norm(Conv2DLayer(\n",
    "                top, num_filters, (3, 3), stride=1, pad=pad, nonlinearity=leaky_rectify))\n",
    "        conv2 = batch_norm(Conv2DLayer(\n",
    "                conv1, num_filters, (3, 3), stride=1, pad=pad, nonlinearity=leaky_rectify))\n",
    "        conv3 = batch_norm(Conv2DLayer(conv2\n",
    "                                       , num_filters, (3, 3), stride=1, pad=pad, nonlinearity=leaky_rectify))\n",
    "        return MaxPool2DLayer(conv3, (2, 2), 2)    \n",
    "    \n",
    "    def conv_4_layer_stack(top, num_filters, pad=1):\n",
    "        conv1 = batch_norm(Conv2DLayer(\n",
    "                top, num_filters, (3, 3), stride=1, pad=pad, nonlinearity=leaky_rectify))\n",
    "        conv2 = batch_norm(Conv2DLayer(\n",
    "                conv1, num_filters, (3, 3), stride=1, pad=pad, nonlinearity=leaky_rectify))\n",
    "        conv3 = batch_norm(Conv2DLayer(\n",
    "                conv2, num_filters, (3, 3), stride=1, pad=pad, nonlinearity=leaky_rectify))\n",
    "        conv4 = batch_norm(Conv2DLayer(\n",
    "                conv3, num_filters, (3, 3), stride=1, pad=pad, nonlinearity=leaky_rectify))\n",
    "        return MaxPool2DLayer(conv4, (2, 2), 2)\n",
    "    \n",
    "    def conv_6_layer_stack(top, num_filters, pad=1):\n",
    "        conv1 = batch_norm(Conv2DLayer(\n",
    "                top, num_filters, (3, 3), stride=1, pad=pad, nonlinearity=leaky_rectify))\n",
    "        conv2 = batch_norm(Conv2DLayer(\n",
    "                conv1, num_filters, (3, 3), stride=1, pad=pad, nonlinearity=leaky_rectify))\n",
    "        conv3 = batch_norm(Conv2DLayer(\n",
    "                conv2, num_filters, (3, 3), stride=1, pad=pad, nonlinearity=leaky_rectify))\n",
    "        conv4 = batch_norm(Conv2DLayer(\n",
    "                conv3, num_filters, (3, 3), stride=1, pad=pad, nonlinearity=leaky_rectify))\n",
    "        conv5 = batch_norm(Conv2DLayer(\n",
    "                conv4, num_filters, (3, 3), stride=1, pad=pad, nonlinearity=leaky_rectify))\n",
    "        conv6 = batch_norm(Conv2DLayer(\n",
    "                conv5, num_filters, (3, 3), stride=1, pad=pad, nonlinearity=leaky_rectify))\n",
    "        return MaxPool2DLayer(conv6, (2, 2), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 8\n",
    "input_layer = InputLayer((None, 1, input_volume_shape[0], input_volume_shape[1]))\n",
    "conv1 = batch_norm(Conv2DDNNLayer(input_layer, 32, (7, 7), \n",
    "                    stride=2, pad=0, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "maxpool1 = MaxPool2DLayer(conv1, (2, 2), 2)\n",
    "\n",
    "conv_stack_1 = conv_2_layer_stack(maxpool1, 64)\n",
    "# dropout1 = DropoutLayer(conv_stack_1, p=0.1)\n",
    "\n",
    "conv_stack_2 = conv_2_layer_stack(conv_stack_1, 128)\n",
    "# dropout2 = DropoutLayer(conv_stack_2, p=0.2)\n",
    "\n",
    "conv_stack_3 = conv_2_layer_stack(conv_stack_2, 256)\n",
    "# dropout3 = DropoutLayer(conv_stack_3, p=0.3)\n",
    "\n",
    "# conv_stack_4 = conv_2_layer_stack(conv_stack_3, 512, pad=0)\n",
    "# dropout4 = DropoutLayer(conv_stack_4, p=0.4)\n",
    "\n",
    "# conv_stack_5 = conv_2_layer_stack(conv_stack_4, 1024, pad=0)\n",
    "# dropout17 = DropoutLayer(conv_stack_5, p=0.5)\n",
    "\n",
    "conv4 = batch_norm(Conv2DDNNLayer(conv_stack_3, 512, (3, 3), \n",
    "        stride=1, pad=0, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "conv5 = batch_norm(Conv2DDNNLayer(conv4, 512, (3, 3), \n",
    "        stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "conv6 = batch_norm(Conv2DDNNLayer(conv5, 512, (3, 3), \n",
    "        stride=1, pad=0, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "conv7 = batch_norm(Conv2DDNNLayer(conv6, 512, (3, 3), \n",
    "        stride=1, pad=1, nonlinearity=leaky_rectify, W=Orthogonal()))\n",
    "maxpool2 = MaxPool2DLayer(conv7, (2, 2), 2)\n",
    "\n",
    "dense18 = DenseLayer(maxpool2, 2048, nonlinearity=None)\n",
    "norm1 = BatchNormLayer(dense18)\n",
    "maxout1 = FeaturePoolLayer(norm1, k)\n",
    "dropout19 = DropoutLayer(maxout1, p=0.5)\n",
    "\n",
    "dense20 = DenseLayer(dropout19, 2048, nonlinearity=None)\n",
    "norm2 = BatchNormLayer(dense20)\n",
    "maxout2 = FeaturePoolLayer(norm2, k)\n",
    "\n",
    "softmax21 = DenseLayer(maxout2, 10, nonlinearity=softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality of Life Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "logging.config.fileConfig(\"logging-training.conf\")\n",
    "\n",
    "def regularization_objective(layers, lambda1=0., lambda2=0., *args, **kwargs):\n",
    "    # default loss\n",
    "    losses = objective(layers, *args, **kwargs)\n",
    "    # get layer weights except for the biases\n",
    "    weights = get_all_params(layers[-1], regularizable=True)\n",
    "    regularization_term = 0.0\n",
    "    # sum of abs weights for L1 regularization\n",
    "    if lambda1 != 0.0:\n",
    "        sum_abs_weights = sum([abs(w).sum() for w in weights])\n",
    "        regularization_term += (lambda1 * sum_abs_weights) \n",
    "    # sum of squares (sum(theta^2))\n",
    "    if lambda2 != 0.0:\n",
    "        sum_squared_weights = (1 / 2.0) * sum([(w ** 2).sum() for w in weights])\n",
    "        regularization_term += (lambda2 * sum_squared_weights)\n",
    "    # add weights to regular loss\n",
    "    losses += regularization_term\n",
    "    return losses\n",
    "\n",
    "def eval_regularization(net):\n",
    "    if net.objective_lambda1 == 0 and net.objective_lambda2 == 0:\n",
    "        return 0\n",
    "    # check the loss if the regularization term is not overpowering the loss\n",
    "    weights = get_all_params(net.layers_[-1], regularizable=True)\n",
    "    # sum of abs weights for L1 regularization\n",
    "    sum_abs_weights = sum([abs(w).sum() for w in weights])\n",
    "    # sum of squares (sum(theta^2))\n",
    "    sum_squared_weights = (1 / 2.0) * sum([(w ** 2).sum() for w in weights])\n",
    "    # add weights to regular loss\n",
    "    regularization_term = (net.objective_lambda1 * sum_abs_weights) \\\n",
    "                          + (net.objective_lambda2 * sum_squared_weights)\n",
    "    return regularization_term\n",
    "\n",
    "\n",
    "def print_regularization_term(net):\n",
    "    if net.objective_lambda1 > 0.0 or net.objective_lambda2 > 0.0:\n",
    "        regularization_term = eval_regularization(net)\n",
    "        print \"Regularization term: {}\".format(regularization_term.eval())\n",
    "\n",
    "def validation_set_loss(_net, _X, _y):\n",
    "    \"\"\"We need this to track the validation loss\"\"\"\n",
    "    _yb = _net.predict_proba(_X)\n",
    "    _y_pred = np.argmax(_yb, axis=1)\n",
    "    _acc = metrics.accuracy_score(_y, _y_pred)\n",
    "    loss = aggregate(categorical_crossentropy(_yb, _y))\n",
    "    loss += eval_regularization(_net)\n",
    "    return loss, _acc\n",
    "\n",
    "\n",
    "def store_model(model_file_name, net):\n",
    "    directory_name = os.path.dirname(model_file_name)\n",
    "    model_file_name = os.path.basename(model_file_name)\n",
    "    if not os.path.exists(directory_name):\n",
    "        os.makedirs(directory_name)\n",
    "    # write model\n",
    "    output_model_file_name = os.path.join(directory_name, model_file_name)\n",
    "    start_write_time = time.time()\n",
    "    if os.path.isfile(output_model_file_name):\n",
    "        os.remove(output_model_file_name)\n",
    "    with open(output_model_file_name, 'wb') as experiment_model:\n",
    "        pickle.dump(net, experiment_model)\n",
    "    total_write_time = time.time() - start_write_time\n",
    "    m, s = divmod(total_write_time, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    logging.log(logging.INFO, \"Duration of saving to disk: %0d:%02d:%02d\", h, m, s)\n",
    "\n",
    "def write_validation_loss_and_store_best(validation_file_name, best_weights_file_name, \n",
    "                                         net, X_val, y_val, best_vloss, best_acc):\n",
    "    # write validation loss\n",
    "    start_validate_time = time.time()\n",
    "    vLoss, vAcc = validation_set_loss(net, X_val, y_val)\n",
    "    loss = vLoss.eval()\n",
    "    current_epoch = net.train_history_[-1]['epoch']\n",
    "    with open(validation_file_name, 'a') as validation_file:\n",
    "        validation_file.write(\"{}, {}, {}\\n\".format(current_epoch, loss, vAcc))\n",
    "\n",
    "    total_validate_time = time.time() - start_validate_time\n",
    "    m, s = divmod(total_validate_time, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    logging.log(logging.INFO, \"Duration of validation: %0d:%02d:%02d\", h, m, s)\n",
    "    \n",
    "    # store best weights here\n",
    "    if loss < best_vloss:\n",
    "        start_bw_time = time.time()\n",
    "        best_vloss = loss\n",
    "        best_acc = vAcc\n",
    "        with open(best_weights_file_name, 'wb') as best_model_file:\n",
    "            pickle.dump(net.get_all_params_values(), best_model_file, -1)\n",
    "            \n",
    "    return best_vloss, best_acc\n",
    "\n",
    "\n",
    "class AdjustVariableWithStepSize(object):\n",
    "    \"\"\"This class adjusts any variable during training\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, start=0.03, steps=3, after_epochs=2000):\n",
    "        self.name = name\n",
    "        self.start = start\n",
    "        self.steps=steps\n",
    "        self.after_epochs=after_epochs\n",
    "        self.ls = []\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if not self.ls:\n",
    "            for i in range(self.steps):\n",
    "                self.ls.extend(np.repeat(self.start/(np.power(10,i)), self.after_epochs))\n",
    "\n",
    "        try:\n",
    "            epoch = train_history[-1]['epoch']\n",
    "            new_value = np.float32(self.ls[epoch - 1])\n",
    "            getattr(nn, self.name).set_value(new_value)\n",
    "        except IndexError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lambda1 = 0.0\n",
    "lambda2 = 5e-3\n",
    "\n",
    "net = NeuralNet(\n",
    "    layers=softmax21,\n",
    "    max_epochs=1,\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=theano.shared(np.float32(0.001)),\n",
    "    update_momentum = 0.99,\n",
    "    # update=adam,\n",
    "    on_epoch_finished=[\n",
    "        EarlyStopping(patience=1000),\n",
    "        AdjustVariableWithStepSize('update_learning_rate', start=0.001, steps=2, after_epochs=8000),\n",
    "    ],\n",
    "    on_training_finished=[\n",
    "        EndTrainingFromEarlyStopping()\n",
    "    ],\n",
    "    objective=regularization_objective,\n",
    "    objective_lambda2=lambda2,\n",
    "    objective_lambda1=lambda1,\n",
    "    batch_iterator_train=BatchIterator(batch_size=100),\n",
    "    train_split=TrainSplit(\n",
    "        eval_size=0.25),\n",
    "    # train_split=TrainSplit(eval_size=0.0),\n",
    "    verbose=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = PrintLayerInfo()\n",
    "net.initialize()\n",
    "# p(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load cnn instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model from the beginning net.vgg.large.l2.5e3.orthog-norm-maxout8-lr.2.steps-size-261\n"
     ]
    }
   ],
   "source": [
    "dir_name = 'net.vgg.large.l2.5e3.orthog-norm-maxout8-lr.2.steps-size-261'\n",
    "validation_file_name = \"{}/vloss-{}.txt\".format(dir_name, dir_name)\n",
    "model_file_name = \"{}/{}.pickle\".format(dir_name, dir_name)\n",
    "best_weights_file_name = \"{}/bw-{}.weights\".format(dir_name, dir_name)\n",
    "if os.path.exists(dir_name):\n",
    "    print \"Model exists. Loading {}.\".format(dir_name)\n",
    "    with open(model_file_name, 'rb') as reader:\n",
    "        net = pickle.load(reader)\n",
    "else:\n",
    "    print \"Training model from the beginning {}\".format(dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "load_best_weights(best_weights_file_name, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from nolearn.lasagne.visualize import plot_loss\n",
    "plt.figure( figsize=(15,9))\n",
    "plt.ylim([0.1,0.5])\n",
    "plt.plot([v['valid_loss'] for v in net.train_history_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# just this time.\n",
    "net.on_epoch_finished.pop(1)\n",
    "print net.on_epoch_finished\n",
    "net.update_learning_rate=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_dir =  \"/media/dylan/Science/Kaggle-Data/distracted_drivers/val/\"\n",
    "X_val, y_val = image_gen_from_dir(val_dir, 40, 10, size=input_volume_shape).next()\n",
    "X_val = X_val.reshape(-1, 1, input_volume_shape[0], input_volume_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 14159722 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "name               size          total    cap.Y    cap.X    cov.Y    cov.X    filter Y    filter X    field Y    field X\n",
      "-----------------  ----------  -------  -------  -------  -------  -------  ----------  ----------  ---------  ---------\n",
      "InputLayer         1x261x261     68121   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "Conv2DDNNLayer     32x128x128   524288   100.00   100.00     2.68     2.68           7           7          7          7\n",
      "BatchNormLayer     32x128x128   524288   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "NonlinearityLayer  32x128x128   524288   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "MaxPool2DLayer     32x64x64     131072   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "Conv2DDNNLayer     64x64x64     262144   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "BatchNormLayer     64x64x64     262144   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "NonlinearityLayer  64x64x64     262144   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "Conv2DDNNLayer     64x64x64     262144   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "BatchNormLayer     64x64x64     262144   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "NonlinearityLayer  64x64x64     262144   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "MaxPool2DDNNLayer  64x32x32      65536   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "Conv2DDNNLayer     128x32x32    131072   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "BatchNormLayer     128x32x32    131072   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "NonlinearityLayer  128x32x32    131072   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "Conv2DDNNLayer     128x32x32    131072   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "BatchNormLayer     128x32x32    131072   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "NonlinearityLayer  128x32x32    131072   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "MaxPool2DDNNLayer  128x16x16     32768   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "Conv2DDNNLayer     256x16x16     65536   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "BatchNormLayer     256x16x16     65536   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "NonlinearityLayer  256x16x16     65536   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "Conv2DDNNLayer     256x16x16     65536   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "BatchNormLayer     256x16x16     65536   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "NonlinearityLayer  256x16x16     65536   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "MaxPool2DDNNLayer  256x8x8       16384   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "Conv2DDNNLayer     512x6x6       18432   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "BatchNormLayer     512x6x6       18432   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "NonlinearityLayer  512x6x6       18432   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "Conv2DDNNLayer     512x6x6       18432   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "BatchNormLayer     512x6x6       18432   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "NonlinearityLayer  512x6x6       18432   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "Conv2DDNNLayer     512x4x4        8192   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "BatchNormLayer     512x4x4        8192   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "NonlinearityLayer  512x4x4        8192   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "Conv2DDNNLayer     512x4x4        8192   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "BatchNormLayer     512x4x4        8192   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "NonlinearityLayer  512x4x4        8192   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "MaxPool2DLayer     512x2x2        2048   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "DenseLayer         2048           2048   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "BatchNormLayer     2048           2048   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "FeaturePoolLayer   256             256   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "DropoutLayer       256             256   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "DenseLayer         2048           2048   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "BatchNormLayer     2048           2048   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "FeaturePoolLayer   256             256   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "DenseLayer         10               10   100.00   100.00   100.00   100.00         261         261        261        261\n",
      "\n",
      "Explanation\n",
      "    X, Y:    image dimensions\n",
      "    cap.:    learning capacity\n",
      "    cov.:    coverage of image\n",
      "    \u001b[35mmagenta\u001b[0m: capacity too low (<1/6)\n",
      "    \u001b[36mcyan\u001b[0m:    image coverage too high (>100%)\n",
      "    \u001b[31mred\u001b[0m:     capacity too low and coverage too high\n",
      "\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1      \u001b[36m35.70711\u001b[0m      \u001b[32m33.73341\u001b[0m      1.05851      0.10000  0.98s\n",
      "2016-07-31 23:07:59,169 - root - INFO - Epoch: 1, Training error: 35.7071113586\n",
      "      2      \u001b[36m35.62210\u001b[0m      33.73750      1.05586      0.10000  0.97s\n",
      "2016-07-31 23:08:00,149 - root - INFO - Epoch: 2, Training error: 35.6221046448\n",
      "      3      \u001b[36m35.18814\u001b[0m      33.73967      1.04293      0.16667  0.98s\n",
      "2016-07-31 23:08:01,145 - root - INFO - Epoch: 3, Training error: 35.1881446838\n",
      "      4      \u001b[36m34.92326\u001b[0m      33.74517      1.03491      0.10000  0.95s\n",
      "2016-07-31 23:08:02,107 - root - INFO - Epoch: 4, Training error: 34.9232635498\n",
      "      5      \u001b[36m34.53671\u001b[0m      33.73351      1.02381      0.06667  0.95s\n",
      "2016-07-31 23:08:03,070 - root - INFO - Epoch: 5, Training error: 34.5367088318\n",
      "      6      \u001b[36m34.31693\u001b[0m      \u001b[32m33.72486\u001b[0m      1.01756      0.16667  0.95s\n",
      "2016-07-31 23:08:04,051 - root - INFO - Epoch: 6, Training error: 34.3169288635\n",
      "      7      34.37460      33.72856      1.01915      0.16667  1.01s\n",
      "2016-07-31 23:08:05,072 - root - INFO - Epoch: 7, Training error: 34.3745956421\n",
      "      8      34.40658      33.73640      1.01987      0.13333  1.07s\n",
      "2016-07-31 23:08:06,168 - root - INFO - Epoch: 8, Training error: 34.406578064\n",
      "      9      \u001b[36m34.21739\u001b[0m      33.74545      1.01399      0.06667  1.11s\n",
      "2016-07-31 23:08:07,293 - root - INFO - Epoch: 9, Training error: 34.2173919678\n",
      "     10      34.22769      33.73416      1.01463      0.03333  1.00s\n",
      "2016-07-31 23:08:08,318 - root - INFO - Epoch: 10, Training error: 34.2276878357\n",
      "     11      34.32386      33.76482      1.01656      0.00000  1.13s\n",
      "2016-07-31 23:08:09,463 - root - INFO - Epoch: 11, Training error: 34.3238601685\n",
      "     12      34.36395      33.89575      1.01381      0.10000  1.11s\n",
      "2016-07-31 23:08:10,584 - root - INFO - Epoch: 12, Training error: 34.3639450073\n",
      "     13      34.49736      34.00295      1.01454      0.10000  1.05s\n",
      "2016-07-31 23:08:11,643 - root - INFO - Epoch: 13, Training error: 34.4973640442\n",
      "     14      34.40776      34.89201      0.98612      0.06667  1.01s\n",
      "2016-07-31 23:08:12,658 - root - INFO - Epoch: 14, Training error: 34.4077644348\n",
      "     15      34.62708      36.87984      0.93892      0.06667  0.94s\n",
      "2016-07-31 23:08:13,605 - root - INFO - Epoch: 15, Training error: 34.62707901\n",
      "     16      34.87041      38.94115      0.89546      0.13333  0.98s\n",
      "2016-07-31 23:08:14,589 - root - INFO - Epoch: 16, Training error: 34.8704109192\n",
      "     17      34.80553      42.91374      0.81106      0.13333  0.97s\n",
      "2016-07-31 23:08:15,575 - root - INFO - Epoch: 17, Training error: 34.8055305481\n",
      "     18      34.65967      45.42543      0.76300      0.10000  0.99s\n",
      "2016-07-31 23:08:16,578 - root - INFO - Epoch: 18, Training error: 34.6596679688\n",
      "     19      34.74032      47.51985      0.73107      0.10000  0.93s\n",
      "2016-07-31 23:08:17,522 - root - INFO - Epoch: 19, Training error: 34.740322113\n",
      "     20      34.52382      48.51399      0.71163      0.10000  0.96s\n",
      "2016-07-31 23:08:18,492 - root - INFO - Epoch: 20, Training error: 34.5238227844\n",
      "     21      34.68174      51.85040      0.66888      0.06667  0.98s\n",
      "2016-07-31 23:08:19,476 - root - INFO - Epoch: 21, Training error: 34.6817359924\n",
      "     22      34.51344      52.82178      0.65339      0.10000  1.10s\n",
      "2016-07-31 23:08:20,601 - root - INFO - Epoch: 22, Training error: 34.5134353638\n",
      "     23      34.35563      51.70115      0.66450      0.13333  1.00s\n",
      "2016-07-31 23:08:21,620 - root - INFO - Epoch: 23, Training error: 34.355632782\n",
      "     24      34.32787      51.50606      0.66648      0.06667  0.96s\n",
      "2016-07-31 23:08:22,594 - root - INFO - Epoch: 24, Training error: 34.3278694153\n",
      "     25      34.24430      48.83182      0.70127      0.10000  0.97s\n",
      "2016-07-31 23:08:23,577 - root - INFO - Epoch: 25, Training error: 34.2443008423\n",
      "     26      34.23243      45.91653      0.74554      0.10000  1.01s\n",
      "2016-07-31 23:08:24,595 - root - INFO - Epoch: 26, Training error: 34.2324295044\n",
      "     27      \u001b[36m34.08209\u001b[0m      48.21726      0.70684      0.13333  0.98s\n",
      "2016-07-31 23:08:25,587 - root - INFO - Epoch: 27, Training error: 34.0820922852\n",
      "     28      34.28476      54.34813      0.63084      0.10000  0.95s\n",
      "2016-07-31 23:08:26,551 - root - INFO - Epoch: 28, Training error: 34.2847557068\n",
      "     29      \u001b[36m33.99178\u001b[0m      66.22639      0.51327      0.10000  1.00s\n",
      "2016-07-31 23:08:27,561 - root - INFO - Epoch: 29, Training error: 33.9917793274\n",
      "     30      \u001b[36m33.98634\u001b[0m      71.18796      0.47742      0.10000  0.98s\n",
      "2016-07-31 23:08:28,548 - root - INFO - Epoch: 30, Training error: 33.9863357544\n",
      "     31      34.20824      94.85815      0.36063      0.10000  0.97s\n",
      "2016-07-31 23:08:29,530 - root - INFO - Epoch: 31, Training error: 34.208240509\n",
      "     32      34.08863      97.63881      0.34913      0.10000  0.92s\n",
      "2016-07-31 23:08:30,460 - root - INFO - Epoch: 32, Training error: 34.088634491\n",
      "     33      34.13584     100.28867      0.34038      0.10000  0.95s\n",
      "2016-07-31 23:08:31,420 - root - INFO - Epoch: 33, Training error: 34.1358413696\n",
      "     34      34.07228      99.97665      0.34080      0.10000  0.99s\n",
      "2016-07-31 23:08:32,437 - root - INFO - Epoch: 34, Training error: 34.0722808838\n",
      "     35      34.13663     106.77155      0.31972      0.10000  0.99s\n",
      "2016-07-31 23:08:33,448 - root - INFO - Epoch: 35, Training error: 34.1366348267\n",
      "     36      34.22134     135.58780      0.25239      0.10000  0.97s\n",
      "2016-07-31 23:08:34,433 - root - INFO - Epoch: 36, Training error: 34.2213439941\n",
      "     37      34.27357     144.03143      0.23796      0.10000  1.03s\n",
      "2016-07-31 23:08:35,475 - root - INFO - Epoch: 37, Training error: 34.2735710144\n",
      "     38      34.06572     135.94006      0.25059      0.10000  0.97s\n",
      "2016-07-31 23:08:36,464 - root - INFO - Epoch: 38, Training error: 34.0657196045\n",
      "     39      34.10125     145.17856      0.23489      0.10000  1.03s\n",
      "2016-07-31 23:08:37,508 - root - INFO - Epoch: 39, Training error: 34.1012458801\n",
      "     40      34.01466     124.50072      0.27321      0.10000  0.98s\n",
      "2016-07-31 23:08:38,503 - root - INFO - Epoch: 40, Training error: 34.0146598816\n"
     ]
    }
   ],
   "source": [
    "image_gen = image_gen_from_dir(data_dir, 10, 10, size=input_volume_shape)\n",
    "gen = random_aug_gen(image_gen, random_aug)\n",
    "threaded_gen = threaded_generator(gen, num_cached=100)\n",
    "\n",
    "ops_every = 500\n",
    "best_acc = 0.0\n",
    "best_vloss = np.inf\n",
    "\n",
    "start_time = time.time()\n",
    "try:\n",
    "    for step, (inputs, targets) in enumerate(threaded_gen):\n",
    "        shape = inputs.shape\n",
    "        net.fit(inputs.reshape(shape[0],1, shape[1], shape[2]), targets)\n",
    "        logging.log(logging.INFO, \"Epoch: {}, Training error: {}\".format(\n",
    "            net.train_history_[-1][\"epoch\"], net.train_history_[-1][\"train_loss\"]))\n",
    "        if (step + 1) % ops_every == 0:\n",
    "            print_regularization_term(net)\n",
    "            store_model(model_file_name, net)\n",
    "            # center validation\n",
    "            best_vloss, best_acc = write_validation_loss_and_store_best(\n",
    "                validation_file_name, best_weights_file_name, net, X_val, y_val, best_vloss, best_acc)\n",
    "            \n",
    "except StopIteration:\n",
    "    # terminate if already early stopping\n",
    "    with open(model_file_name, 'wb') as writer:\n",
    "        pickle.dump(net, writer)\n",
    "    total_time = time.time() - start_time \n",
    "    print(\"Training successful by early stopping. Elapsed: {}\".format(total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from notebook_functions import plot_validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_validation_loss(net, validation_file_name, ylim=[0, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
